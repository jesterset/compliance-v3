{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import AsyncElasticsearch, exceptions\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# Provided Elasticsearch URL\n",
    "es_url = \"https://elastic:NF7Ne7F691OSKwJNcGDNLQjw@04ae44a42e8e437abd819f24a3cd1015.eastus2.azure.elastic-cloud.com:433\"\n",
    "\n",
    "# Parse the URL\n",
    "parsed_url = urlparse(es_url)\n",
    "\n",
    "# Extract components\n",
    "scheme = parsed_url.scheme\n",
    "host = parsed_url.hostname\n",
    "port = parsed_url.port\n",
    "username = parsed_url.username\n",
    "password = parsed_url.password\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = AsyncElasticsearch(\"https://04ae44a42e8e437abd819f24a3cd1015.eastus2.azure.elastic-cloud.com:443/\", basic_auth=('elastic', 'NF7Ne7F691OSKwJNcGDNLQjw'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object AsyncElasticsearch.index at 0x10794d1c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = {\n",
    "    \"sanitiztion_term\": \"example term\",\n",
    "    \"entitiy\": \"example entity\"\n",
    "}\n",
    "\n",
    "es.index(index='regex_rules_index', body=sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'emp_id': '12345678',\n",
       "  'session_id': '55439421-fc1a-4f29-91c3-ee956e512abf',\n",
       "  'message_id': 'b3115cfe-ca1e-4897-8169-69c5dc7591ae',\n",
       "  'input': 'top 5 ways to master javascript',\n",
       "  'timestamp': datetime.datetime(2024, 9, 12, 1, 1, 1),\n",
       "  'feedback_rating_timestamp': datetime.datetime(2024, 9, 12, 1, 2, 2),\n",
       "  'output': 'Mastering JavaScript can be a rewarding journey! Here are the top 5 ways to get there:\\n\\n1. **Self-Guided Websites and Courses**: Platforms like [freeCodeCamp](https://www.freecodecamp.org/), [Codecademy](https://www.codecademy.com/), and [Udemy](https://www.udemy.com/) offer comprehensive JavaScript courses that you can follow at your own pace³.\\n\\n2. **Books**: Reading books like \"Eloquent JavaScript\" by Marijn Haverbeke and \"JavaScript: The Good Parts\" by Douglas Crockford can provide deep insights into the language³.\\n\\n3. **Coding Boot Camps**: Intensive coding boot camps, such as those offered by [Fullstack Academy](https://www.fullstackacademy.com/) and [General Assembly](https://generalassemb.ly/), can accelerate your learning with structured, immersive programs³.\\n\\n4. **Meetups and Networking Events**: Engaging with the JavaScript community through meetups, conferences, and online forums like Stack Overflow can help you learn from others and stay updated with the latest trends³.\\n\\n5. **Starting Your Own Projects**: Building your own projects is one of the best ways to apply what you\\'ve learned. Start with small projects and gradually take on more complex ones to solidify your understanding³.\\n\\nWhich of these methods do you think would work best for you?\\n\\nSource: Conversation with Copilot, 2024-09-12\\n(1) The 5 Best Ways to Learn JavaScript Fast (For Beginners). https://techbootcamps.utexas.edu/blog/best-ways-to-learn-javascript/.\\n(2) The best ways to master JavaScript - Educative. https://www.educative.io/blog/master-javascript.\\n(3) How to Learn JavaScript Effectively – Tips and Learning Strategies. https://www.freecodecamp.org/news/how-to-learn-javascript-effectively/.\\n(4) 8 Best Ways to Learn JavaScript in 2024 - For Beginners - Fullstack Academy. https://www.fullstackacademy.com/blog/best-ways-to-learn-javascript-for-beginners.',\n",
       "  'feedback_rating': None,\n",
       "  'chat_type': 'text'},\n",
       " {'id': 2,\n",
       "  'emp_id': '12345678',\n",
       "  'session_id': '633656ba-3b7e-496a-a83b-8725087836ae',\n",
       "  'message_id': 'f6cf82db-570c-4770-a4f9-d5f927b3db91',\n",
       "  'input': 'summarize this document for me',\n",
       "  'timestamp': datetime.datetime(2024, 9, 12, 2, 2, 2),\n",
       "  'feedback_rating_timestamp': datetime.datetime(2024, 9, 12, 2, 3, 3),\n",
       "  'output': 'Sure! Here are the top 5 ways to master JavaScript:\\n\\n1. **Online Courses**: Use platforms like freeCodeCamp, Codecademy, and Udemy.\\n2. **Books**: Read \"Eloquent JavaScript\" and \"JavaScript: The Good Parts.\"\\n3. **Boot Camps**: Attend intensive programs like those from Fullstack Academy and General Assembly.\\n4. **Community Engagement**: Join meetups, conferences, and forums.\\n5. **Personal Projects**: Build your own projects to apply your knowledge.\\n\\nWhich method do you find most appealing?',\n",
       "  'feedback_rating': None,\n",
       "  'chat_type': 'file'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import psycopg\n",
    "from psycopg.rows import dict_row\n",
    "\n",
    "# Install psycopg[binary] if not already installed\n",
    "# pip install psycopg[binary]\n",
    "\n",
    "# Get the PostgreSQL URL from environment variables\n",
    "POSTGRES_URL = os.getenv('POSTGRES_URL', 'postgresql://postgres.ecaazettexwdvahwhaen:zG9Dtbm0xuL5xmm4@aws-0-ca-central-1.pooler.supabase.com:6543/postgres')\n",
    "\n",
    "async def fetch_chat_messages():\n",
    "    # Connect to the PostgreSQL database\n",
    "    async with await psycopg.AsyncConnection.connect(POSTGRES_URL) as conn:\n",
    "        async with conn.cursor(row_factory=dict_row) as cur:\n",
    "            # Execute the query\n",
    "            await cur.execute(\"SELECT * FROM chat_messages\")\n",
    "            # Fetch all results\n",
    "            results = await cur.fetchall()\n",
    "            return results\n",
    "\n",
    "# Run the async function\n",
    "await fetch_chat_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'created_at': datetime.datetime(2024, 9, 12, 1, 1, 1),\n",
       "  'active': True,\n",
       "  'rule': 'questions that are forward-looking or predictive are prohibited.'},\n",
       " {'id': 2,\n",
       "  'created_at': datetime.datetime(2024, 9, 12, 2, 2, 2),\n",
       "  'active': True,\n",
       "  'rule': 'questions that ask to generate ratings, price targets, estimates, or similar recommendations are prohibited.'},\n",
       " {'id': 3,\n",
       "  'created_at': datetime.datetime(2024, 9, 12, 3, 3, 3),\n",
       "  'active': True,\n",
       "  'rule': \"questions that include information that is confidential or non-public relating to J.P. Morgan, J.P. Morgan clients, employees, contract workers, third parties, or any other topic are prohibited. Examples include J.P. Morgan's financial information, client and employee personal information, client trade data (live or historical), business plans or strategies, pending product launches, pitchbooks, partnerships or contracts with third parties, and employment relationships.\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import psycopg\n",
    "from psycopg.rows import dict_row\n",
    "\n",
    "# Install psycopg[binary] if not already installed\n",
    "# pip install psycopg[binary]\n",
    "\n",
    "# Get the PostgreSQL URL from environment variables\n",
    "POSTGRES_URL = os.getenv('POSTGRES_URL', 'postgresql://postgres.ecaazettexwdvahwhaen:zG9Dtbm0xuL5xmm4@aws-0-ca-central-1.pooler.supabase.com:6543/postgres')\n",
    "\n",
    "async def fetch_chat_messages():\n",
    "    # Connect to the PostgreSQL database\n",
    "    async with await psycopg.AsyncConnection.connect(POSTGRES_URL) as conn:\n",
    "        async with conn.cursor(row_factory=dict_row) as cur:\n",
    "            # Execute the query\n",
    "            await cur.execute(\"SELECT * FROM compliance_rules\")\n",
    "            # Fetch all results\n",
    "            results = await cur.fetchall()\n",
    "            return results\n",
    "\n",
    "# Run the async function\n",
    "await fetch_chat_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/zm9_s1w50111jf7dyzngrh980000gn/T/ipykernel_42749/964134472.py:50: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  await es.indices.create(index=index_name, body=body, ignore=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created index: regex_rules_index_v2\n",
      "Indexed document 0\n",
      "Indexed document 1\n",
      "Indexed document 2\n",
      "Reindexed data from regex_rules_index to regex_rules_index_v2\n",
      "Updated document 1\n",
      "No matches found.\n"
     ]
    }
   ],
   "source": [
    "index_name = \"regex_rules_index_v2\"  # New index name\n",
    "\n",
    "# Step 1: Create the Index with the Mapping (No Change)\n",
    "async def create_index():\n",
    "    body = {\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"filter\": {\n",
    "                    \"synonym_filter\": {\n",
    "                        \"type\": \"synonym\",\n",
    "                        \"synonyms\": [\"predict, forecast, anticipate\"]\n",
    "                    }\n",
    "                },\n",
    "                \"analyzer\": {\n",
    "                    \"custom_synonym_analyzer\": {\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\",\n",
    "                        \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"sanitiztion_term\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\n",
    "                        \"stemmed\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"english\"  # Stemming for better match flexibility\n",
    "                        },\n",
    "                        \"synonym\": {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"custom_synonym_analyzer\"  # Synonyms during indexing\n",
    "                        },\n",
    "                        \"raw\": {\n",
    "                            \"type\": \"keyword\"  # Exact matches\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"entitiy\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create index\n",
    "    await es.indices.create(index=index_name, body=body, ignore=400)\n",
    "    print(f\"Created index: {index_name}\")\n",
    "\n",
    "# Step 2: Index Sample Data (No Change)\n",
    "async def load_data():\n",
    "    sample_data = [\n",
    "        {\"sanitiztion_term\": \"predictive\", \"entitiy\": \"sec\"},\n",
    "        {\"sanitiztion_term\": \"forward-looking\", \"entitiy\": \"sec\"},\n",
    "        {\"sanitiztion_term\": \"example term\", \"entitiy\": \"example entity\"},\n",
    "    ]\n",
    "\n",
    "    # Index documents\n",
    "    for i, doc in enumerate(sample_data):\n",
    "        await es.index(index=index_name, id=i, document=doc)\n",
    "        print(f\"Indexed document {i}\")\n",
    "\n",
    "# Step 3: Reindex Data from Old Index (No Change)\n",
    "async def reindex_data():\n",
    "    old_index = \"regex_rules_index\"\n",
    "    new_index = index_name\n",
    "\n",
    "    body = {\n",
    "        \"source\": {\"index\": old_index},\n",
    "        \"dest\": {\"index\": new_index}\n",
    "    }\n",
    "\n",
    "    await es.reindex(body=body, wait_for_completion=True)\n",
    "    print(f\"Reindexed data from {old_index} to {new_index}\")\n",
    "\n",
    "# Step 4: Update Document (No Change)\n",
    "async def update_document(doc_id, new_data):\n",
    "    await es.update(index=index_name, id=doc_id, body={\"doc\": new_data})\n",
    "    print(f\"Updated document {doc_id}\")\n",
    "\n",
    "# Step 5: Query with Query-Time Synonyms and Boosting\n",
    "async def query_with_synonyms(query_text):\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_text,\n",
    "                \"fields\": [\n",
    "                    \"sanitiztion_term^3\",         # Boost sanitization term matches\n",
    "                    \"sanitiztion_term.synonym^2\",  # Synonym boosted, but lower than sanitiztion_term\n",
    "                    \"sanitiztion_term.stemmed\",    # Allow for stemming matches\n",
    "                    \"entitiy\"                      # Allow entity matches too\n",
    "                ],\n",
    "                \"fuzziness\": \"AUTO\",              # Allow for fuzzy matches\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = await es.search(index=index_name, body=body)\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    if hits:\n",
    "        print(f\"Total hits: {len(hits)}\")\n",
    "        for hit in hits:\n",
    "            print(f\"Match: {hit['_source']}, Score: {hit['_score']}\")\n",
    "    else:\n",
    "        print(\"No matches found.\")\n",
    "\n",
    "# Step 6: Test Query with \"Can you predict the price of Tesla\"\n",
    "async def test_query():\n",
    "    query_text = \"can you predict the price of Tesla\"\n",
    "    await query_with_synonyms(query_text)\n",
    "\n",
    "# Run all the steps\n",
    "async def main():\n",
    "    await create_index()\n",
    "    await load_data()\n",
    "    await reindex_data()  # Reindex only if needed\n",
    "    await update_document(1, {\"sanitiztion_term\": \"updated term\"})  # Update sample doc\n",
    "    await test_query()  # Test query with synonym\n",
    "\n",
    "# Run the script\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_with_synonyms(query_text):\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query_text,\n",
    "                \"fields\": [\n",
    "                    \"sanitiztion_term^3\",         # Boost sanitization term matches\n",
    "                    \"sanitiztion_term.synonym^2\",  # Synonym boosted, but lower than sanitiztion_term\n",
    "                    \"sanitiztion_term.stemmed\",    # Allow for stemming matches\n",
    "                ],\n",
    "                \"fuzziness\": \"AUTO\",              # Allow for fuzzy matches\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = await es.search(index=index_name, body=body)\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    if hits:\n",
    "        print(f\"Total hits: {len(hits)}\")\n",
    "        for hit in hits:\n",
    "            print(f\"Match: {hit['_source']}, Score: {hit['_score']}\")\n",
    "    else:\n",
    "        print(\"No matches found.\")\n",
    "\n",
    "# Step 6: Test Query with \"Can you predict the price of Tesla\"\n",
    "async def test_query():\n",
    "    query_text = \"what the forward guidance for the price target of Tesla\"\n",
    "    await query_with_synonyms(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits: 1\n",
      "Match: {'sanitiztion_term': 'forward-looking', 'entitiy': 'sec'}, Score: 2.7199469\n"
     ]
    }
   ],
   "source": [
    "await test_query()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'regex_rules_index_v2' already exists.\n",
      "Index 'regex_rules_index_v2' closed successfully.\n",
      "Settings for index 'regex_rules_index_v2' updated successfully.\n",
      "Index 'regex_rules_index_v2' opened successfully.\n",
      "Mapping for index 'regex_rules_index_v2' updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the index name\n",
    "index_name = 'regex_rules_index_v2'\n",
    "\n",
    "# Create the index if it does not exist\n",
    "async def create_index():\n",
    "    if not await es.indices.exists(index=index_name):\n",
    "        index_body = {\n",
    "            \"settings\": {\n",
    "                \"analysis\": {\n",
    "                    \"filter\": {\n",
    "                        \"synonym_filter\": {\n",
    "                            \"type\": \"synonym\",\n",
    "                            \"synonyms\": [\"predict, forecast, anticipate\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"analyzer\": {\n",
    "                        \"custom_synonym_analyzer\": {\n",
    "                            \"type\": \"custom\",\n",
    "                            \"tokenizer\": \"standard\",\n",
    "                            \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        await es.indices.create(index=index_name, body=index_body)\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "# Close the index\n",
    "async def close_index():\n",
    "    if await es.indices.exists(index=index_name):\n",
    "        await es.indices.close(index=index_name)\n",
    "        print(f\"Index '{index_name}' closed successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' does not exist to close.\")\n",
    "\n",
    "# Update the index settings\n",
    "async def update_settings():\n",
    "    if await es.indices.exists(index=index_name):\n",
    "        settings_body = {\n",
    "            \"analysis\": {\n",
    "                \"filter\": {\n",
    "                    \"synonym_filter\": {\n",
    "                        \"type\": \"synonym\",\n",
    "                        \"synonyms\": [\"predict, forecast, anticipate\"]\n",
    "                    }\n",
    "                },\n",
    "                \"analyzer\": {\n",
    "                    \"custom_synonym_analyzer\": {\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\",\n",
    "                        \"filter\": [\"lowercase\", \"synonym_filter\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        await es.indices.put_settings(index=index_name, body=settings_body)\n",
    "        print(f\"Settings for index '{index_name}' updated successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' does not exist to update settings.\")\n",
    "\n",
    "# Reopen the index\n",
    "async def open_index():\n",
    "    if await es.indices.exists(index=index_name):\n",
    "        await es.indices.open(index=index_name)\n",
    "        print(f\"Index '{index_name}' opened successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' does not exist to open.\")\n",
    "\n",
    "# Update the index mapping\n",
    "async def update_mapping():\n",
    "    mapping_body = {\n",
    "        \"properties\": {\n",
    "            \"sanitization_term\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\n",
    "                    \"stemmed\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"english\"\n",
    "                    },\n",
    "                    \"synonym\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"custom_synonym_analyzer\"\n",
    "                    },\n",
    "                    \"raw\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"entity\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"standard\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if await es.indices.exists(index=index_name):\n",
    "        await es.indices.put_mapping(index=index_name, body=mapping_body)\n",
    "        print(f\"Mapping for index '{index_name}' updated successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' does not exist to update mapping.\")\n",
    "\n",
    "# Run all the steps\n",
    "async def main():\n",
    "    await create_index()\n",
    "    await close_index()\n",
    "    await update_settings()\n",
    "    await open_index()\n",
    "    await update_mapping()\n",
    "\n",
    "# Run the script\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed document 0\n",
      "Indexed document 1\n",
      "Indexed document 2\n"
     ]
    }
   ],
   "source": [
    "sample_data = [\n",
    "\n",
    "    {\"sanitiztion_term\": \"predictive\", \"entitiy\": \"sec\"},\n",
    "    {\"sanitiztion_term\": \"forward-looking\", \"entitiy\": \"sec\"},\n",
    "    {\"sanitiztion_term\": \"example term\", \"entitiy\": \"example entity\"},\n",
    "]\n",
    "\n",
    "# Index documents\n",
    "for i, doc in enumerate(sample_data):\n",
    "    await es.index(index=index_name, id=i, document=doc)\n",
    "    print(f\"Indexed document {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compliance_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
